{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importación de librerías y configuración inicial**\n",
    "\n",
    "En este bloque se realiza la importación de las librerías necesarias para el análisis y modelado de datos. Estas librerías incluyen:\n",
    "\n",
    "- `pandas` para la manipulación de datos.\n",
    "- `scikit-learn` para la construcción de pipelines, preprocesamiento, y modelado con clasificadores como `RandomForestClassifier` y `GradientBoostingClassifier`.\n",
    "- `xgboost` para el modelo de clasificación basado en boosting.\n",
    "- `matplotlib.pyplot` para la visualización.\n",
    "- `scipy.stats.boxcox` para aplicar transformaciones de Box-Cox a los datos.\n",
    "- Utilidades adicionales como `GridSearchCV` y `RandomizedSearchCV` para la optimización de hiperparámetros.\n",
    "\n",
    "También se configura una semilla (`SEED`) para garantizar la reproducibilidad de los resultados.\n",
    "\n",
    "Este bloque establece las bases necesarias para los pasos posteriores del análisis y modelado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente y semilla ajustada.\n"
     ]
    }
   ],
   "source": [
    "# --- Manejo de datos ---\n",
    "import pandas as pd  # Para manipulación y análisis de datos\n",
    "import numpy as np  # Para operaciones matemáticas y manejo de arrays\n",
    "\n",
    "# --- Preprocesamiento de datos ---\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder  # Para escalado y codificación de etiquetas\n",
    "from sklearn.utils import resample  # Para oversampling clásico\n",
    "from scipy.stats import boxcox  # Para transformación Box-Cox\n",
    "\n",
    "# --- Construcción de pipelines y transformaciones ---\n",
    "from sklearn.pipeline import Pipeline  # Para construir pipelines\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin  # Para crear estimadores personalizados\n",
    "\n",
    "# --- Modelos ---\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier  # Modelos de ensamble\n",
    "from xgboost import XGBClassifier  # Modelo XGBoost\n",
    "from sklearn.linear_model import LogisticRegression  # Modelo de regresión logística\n",
    "\n",
    "# --- Evaluación de modelos ---\n",
    "from sklearn.metrics import f1_score  # Métrica F1 para evaluar el rendimiento\n",
    "from sklearn.model_selection import train_test_split  # Para dividir los datos en entrenamiento y prueba\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV  # Para búsqueda de hiperparámetros\n",
    "from sklearn.model_selection import StratifiedKFold  # Validación cruzada estratificada\n",
    "\n",
    "# --- Visualización ---\n",
    "import matplotlib.pyplot as plt  # Para visualización de datos\n",
    "\n",
    "# --- Configuración de la semilla ---\n",
    "SEED = 42  # Fijar semilla para reproducibilidad\n",
    "np.random.seed(SEED)  # Semilla para NumPy\n",
    "\n",
    "# --- Mensaje de éxito ---\n",
    "print(\"Librerías importadas correctamente y semilla ajustada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clases personalizadas para preprocesamiento y modelado**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque se implementan diversas clases personalizadas que forman parte del pipeline de preprocesamiento y modelado. Estas clases están diseñadas como transformadores compatibles con `scikit-learn`, permitiendo integrarlas fácilmente en pipelines.\n",
    "\n",
    "1. **RemoveDuplicates**: \n",
    "   - Elimina registros duplicados del dataset.\n",
    "   - No requiere entrenamiento.\n",
    "\n",
    "2. **HandleOutliers**:\n",
    "   - Maneja valores atípicos (`outliers`) mediante:\n",
    "     - Limitación superior (capped) para la columna `density`.\n",
    "     - Eliminación de outliers en `total_sulfur_dioxide` usando el método IQR.\n",
    "   - Incluye opciones para desactivar este paso y personalizar el límite de `density`.\n",
    "\n",
    "3. **FeatureTransformations**:\n",
    "   - Aplica transformaciones específicas en las características del dataset, como:\n",
    "     - Transformaciones logarítmicas y raíz cuadrada para reducir la variabilidad.\n",
    "     - Estandarización de `citric_acid` usando `StandardScaler`.\n",
    "     - Transformación de Box-Cox en columnas como `chlorides` y `sulphates`.\n",
    "\n",
    "4. **FeatureCombinations**:\n",
    "   - Genera nuevas características combinando columnas existentes, por ejemplo:\n",
    "     - Relación `alcohol/density`.\n",
    "     - Relación `free_sulfur_dioxide/total_sulfur_dioxide`.\n",
    "     - Identificador binario si `citric_acid` es cero.\n",
    "   - Permite eliminar las columnas originales tras crear las combinaciones.\n",
    "\n",
    "5. **SklearnXGBClassifier**:\n",
    "   - Corrige incompatibilidades entre `XGBoost` y versiones más recientes de `scikit-learn`.\n",
    "   - Implementa métodos como `fit`, `predict` y `predict_proba` para garantizar compatibilidad con pipelines y validaciones cruzadas.\n",
    "\n",
    "Estas clases personalizadas permiten un manejo flexible y escalable de los datos, facilitando el preprocesamiento y la construcción de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase personalizada para eliminar duplicados\n",
    "class RemoveDuplicates(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Esta clase elimina duplicados del dataset.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        # No necesita entrenamiento, simplemente devuelve self\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Elimina los duplicados del dataset y devuelve los datos procesados\n",
    "        return X.drop_duplicates()\n",
    "\n",
    "# Clase personalizada para manejar los outliers\n",
    "class HandleOutliers(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Esta clase maneja los outliers:\n",
    "    - Aplica un capped (límite) a 'density'.\n",
    "    - Elimina 'total sulfur dioxide'.\n",
    "    - Mantiene 'chlorides' intacto.\n",
    "    \"\"\"\n",
    "    def __init__(self, active=True, density_cap=1.05):\n",
    "        \"\"\"\n",
    "        - active: Activa/desactiva el manejo de outliers.\n",
    "        - density_cap: Límite superior para 'density'.\n",
    "        \"\"\"\n",
    "        self.active = active\n",
    "        self.density_cap = density_cap\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No necesita entrenamiento, solo devuelve self\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Si el bloque está desactivado, devolvemos X sin cambios\n",
    "        if not self.active:\n",
    "            return X\n",
    "        \n",
    "        # Hacemos una copia del dataset para evitar modificar el original\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Aplicamos el capped a 'density'\n",
    "        if 'density' in X.columns:\n",
    "            X['density'] = X['density'].clip(upper=self.density_cap)\n",
    "        \n",
    "        # Eliminamos outliers de 'total sulfur dioxide' usando IQR\n",
    "        if 'total_sulfur_dioxide' in X.columns:\n",
    "            q1 = X['total_sulfur_dioxide'].quantile(0.25)\n",
    "            q3 = X['total_sulfur_dioxide'].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "            X = X[(X['total_sulfur_dioxide'] >= lower_bound) & (X['total_sulfur_dioxide'] <= upper_bound)]\n",
    "        \n",
    "        # No tocamos 'chlorides'\n",
    "        return X\n",
    "\n",
    "# Clase personalizada para transformar las características\n",
    "class FeatureTransformations(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Clase para realizar transformaciones específicas en las columnas.\n",
    "    \"\"\"\n",
    "    def __init__(self, scale=False):\n",
    "        self.scale = scale\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.scale:\n",
    "            # Ajustamos el escalador a todas las columnas numéricas excepto 'quality' y 'quality_encoded'\n",
    "            self.numeric_columns = [col for col in X.columns if X[col].dtype in ['float64', 'int64'] \\\n",
    "                                    and col not in ['quality', 'quality_encoded']]\n",
    "            self.scaler.fit(X[self.numeric_columns])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Aplicamos las transformaciones específicas\n",
    "        if 'fixed_acidity' in X.columns:\n",
    "            X['fixed_acidity'] = np.log1p(X['fixed_acidity'])  # Logaritmo 1p\n",
    "        if 'volatile_acidity' in X.columns:\n",
    "            X['volatile_acidity'] = np.sqrt(X['volatile_acidity'])  # Raíz cuadrada\n",
    "        if 'residual_sugar' in X.columns:\n",
    "            X['residual_sugar'] = np.log1p(X['residual_sugar'])  # Logaritmo 1p\n",
    "        if 'chlorides' in X.columns:\n",
    "            X['chlorides'], _ = boxcox(X['chlorides'] + 1e-6)  # Box-Cox (evitamos ceros sumando un pequeño valor)\n",
    "        if 'sulphates' in X.columns:\n",
    "            X['sulphates'], _ = boxcox(X['sulphates'] + 1e-6)  # Box-Cox (igual que antes)\n",
    "\n",
    "        # Escalado opcional de todas las columnas numéricas\n",
    "        if self.scale:\n",
    "            X[self.numeric_columns] = self.scaler.transform(X[self.numeric_columns])\n",
    "\n",
    "        return X\n",
    "\n",
    "class FeatureCombinations(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Clase para generar combinaciones de variables y eliminar las originales.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        # No necesitamos calcular nada, devolvemos self\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Crear nueva variable: alcohol / density\n",
    "        if 'alcohol' in X.columns and 'density' in X.columns:\n",
    "            X['alcohol_density_ratio'] = X['alcohol'] / X['density']\n",
    "        \n",
    "        # Crear nueva variable: free sulfur dioxide / total sulfur dioxide\n",
    "        if 'free_sulfur_dioxide' in X.columns and 'total_sulfur_dioxide' in X.columns:\n",
    "            X['sulfur_ratio'] = X['free_sulfur_dioxide'] / X['total_sulfur_dioxide']\n",
    "        \n",
    "        # Crear nueva variable: citric0\n",
    "        if 'citric acid' in X.columns:\n",
    "            X['citric_is_zero'] = (X['citric_acid'] == 0).astype(int)\n",
    "        \n",
    "        # Eliminar columnas originales\n",
    "        columns_to_drop = ['alcohol', 'density', 'free_sulfur_dioxide', 'total_sulfur_dioxide']\n",
    "        # X = X.drop(columns=[col for col in columns_to_drop if col in X.columns])\n",
    "        \n",
    "        return X\n",
    "    \n",
    "# CLase para fix la incompatibilidad de XGBoost con Scikit-learn 1.6\n",
    "\n",
    "\n",
    "\n",
    "class SklearnXGBClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = XGBClassifier(**kwargs)\n",
    "        self.classes_ = None  # Inicializamos el atributo classes_\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        self.model.fit(X, y, **kwargs)\n",
    "        self.classes_ = self.model.classes_  # Asignamos las clases tras el entrenamiento\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.model.get_params(deep)\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.model.set_params(**params)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Funciones personalizadas para oversampling y evaluación de modelos**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque se implementan dos funciones personalizadas para mejorar el manejo de desequilibrios en las clases y la evaluación de modelos:\n",
    "\n",
    "1. **oversample_data**:\n",
    "   - Realiza *oversampling* clásico duplicando las instancias de las clases minoritarias en el conjunto de datos.\n",
    "   - Se combinan las características (`X`) y el objetivo (`y`) en un solo DataFrame para realizar el muestreo, y luego se separan nuevamente.\n",
    "   - Esta función es útil para equilibrar las clases antes de entrenar los modelos.\n",
    "\n",
    "2. **probar_modelo_con_grid**:\n",
    "   - Entrena un modelo utilizando `GridSearchCV`, que realiza una búsqueda exhaustiva de hiperparámetros.\n",
    "   - Acepta un parámetro `modo` para seleccionar diferentes estrategias de balanceo de clases:\n",
    "     - **oversampling**: Realiza *oversampling* antes de entrenar.\n",
    "     - **balance**: Asigna pesos a las clases según su frecuencia en el conjunto de entrenamiento.\n",
    "     - **ninguno**: No se realiza ninguna estrategia adicional.\n",
    "   - Devuelve la puntuación F1 ponderada, los mejores parámetros encontrados y el mejor modelo.\n",
    "\n",
    "3. **probar_modelo_con_random_search**:\n",
    "   - Similar a la función anterior, pero usa `RandomizedSearchCV` para probar combinaciones aleatorias de parámetros.\n",
    "   - Acepta el mismo parámetro `modo` para realizar *oversampling* o balanceo según sea necesario.\n",
    "   - Devuelve la puntuación F1 ponderada, los mejores parámetros y el mejor modelo.\n",
    "\n",
    "Estas funciones permiten una búsqueda eficiente de los mejores modelos mientras manejan desequilibrios en las clases de manera flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_data(X, y):\n",
    "    \"\"\"\n",
    "    Realiza oversampling clásico duplicando registros de clases minoritarias.\n",
    "    \"\"\"\n",
    "    # Combinamos X e y en un solo dataframe temporal\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    target_col = y.name  # Guardamos el nombre de la columna objetivo\n",
    "\n",
    "    # Encontramos la clase mayoritaria\n",
    "    max_count = data[target_col].value_counts().max()\n",
    "\n",
    "    # Aplicamos oversampling duplicando las clases minoritarias\n",
    "    data_resampled = pd.DataFrame()\n",
    "    for clase in data[target_col].unique():\n",
    "        clase_data = data[data[target_col] == clase]\n",
    "        clase_upsampled = resample(clase_data, replace=True, n_samples=max_count, random_state=SEED)\n",
    "        data_resampled = pd.concat([data_resampled, clase_upsampled])\n",
    "    \n",
    "    # Separamos X e y de nuevo\n",
    "    X_resampled = data_resampled.drop(target_col, axis=1)\n",
    "    y_resampled = data_resampled[target_col]\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Ajustamos la función de modelos para usar el nuevo oversampling\n",
    "def probar_modelo_con_grid(modelo, X_train, y_train, X_test, y_test, param_grid, modo=\"ninguno\"):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo con búsqueda de hiperparámetros.\n",
    "    - modelo: Modelo a entrenar.\n",
    "    - X_train, y_train: Datos de entrenamiento.\n",
    "    - X_test, y_test: Datos de prueba.\n",
    "    - param_grid: Diccionario con los parámetros para GridSearch.\n",
    "    - modo: Puede ser 'oversampling', 'balance' o 'ninguno'.\n",
    "    \"\"\"\n",
    "    sample_weight = None\n",
    "\n",
    "    if modo == \"oversampling\":\n",
    "        X_train, y_train = oversample_data(X_train, y_train)\n",
    "\n",
    "    elif modo == \"balance\":\n",
    "        class_weights = {cls: len(y_train) / (len(set(y_train)) * sum(y_train == cls)) for cls in set(y_train)}\n",
    "        sample_weight = y_train.map(class_weights) if hasattr(y_train, 'map') else [class_weights[cls] for cls in y_train]\n",
    "\n",
    "    stratified_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        modelo,\n",
    "        param_grid,\n",
    "        scoring='f1_weighted',\n",
    "        cv=stratified_cv,\n",
    "        n_jobs=-1,\n",
    "        error_score='raise',\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        grid_search.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    else:\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return f1, grid_search.best_params_, best_model\n",
    "\n",
    "def probar_modelo_con_random_search(modelo, X_train, y_train, X_test, y_test, param_distributions, n_iter=50, modo=\"ninguno\"):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo con búsqueda aleatoria de hiperparámetros.\n",
    "    - modelo: Modelo a entrenar.\n",
    "    - X_train, y_train: Datos de entrenamiento.\n",
    "    - X_test, y_test: Datos de prueba.\n",
    "    - param_distributions: Diccionario con las distribuciones de parámetros para RandomizedSearch.\n",
    "    - n_iter: Número de combinaciones a probar.\n",
    "    - modo: Puede ser 'oversampling', 'balance' o 'ninguno'.\n",
    "    \"\"\"\n",
    "    sample_weight = None\n",
    "\n",
    "    if modo == \"oversampling\":\n",
    "        X_train, y_train = oversample_data(X_train, y_train)\n",
    "\n",
    "    elif modo == \"balance\":\n",
    "        class_weights = {cls: len(y_train) / (len(set(y_train)) * sum(y_train == cls)) for cls in set(y_train)}\n",
    "        sample_weight = y_train.map(class_weights) if hasattr(y_train, 'map') else [class_weights[cls] for cls in y_train]\n",
    "\n",
    "    stratified_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Configuramos RandomizedSearch\n",
    "    random_search = RandomizedSearchCV(\n",
    "        modelo,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,  # Número de combinaciones a probar\n",
    "        scoring='f1_weighted',\n",
    "        cv=stratified_cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=SEED,\n",
    "        error_score='raise'\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Entrenamos con sample_weight si es necesario\n",
    "    if sample_weight is not None:\n",
    "        random_search.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    else:\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Usamos el mejor modelo encontrado\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return f1, random_search.best_params_, best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados esperados\n",
    "Las funciones de evaluación (`GridSearchCV` y `RandomizedSearchCV`) devolverán los siguientes resultados:\n",
    "\n",
    "- **Puntuación F1 ponderada**: La métrica de evaluación usada para evaluar el rendimiento del modelo considerando el balance entre precisión y recall en clases desbalanceadas.\n",
    "- **Mejores parámetros**: Los mejores parámetros encontrados por las búsquedas de hiperparámetros (ya sea por *grid search* o *random search*).\n",
    "- **Mejor modelo**: El modelo entrenado con los mejores parámetros.\n",
    "\n",
    "El *oversampling* y las estrategias de balanceo de clases ayudarán a mejorar la precisión en clases minoritarias, lo que se reflejará en una puntuación F1 más alta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Carga y balanceo del dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este bloque, se carga el conjunto de datos de vinos desde un archivo CSV y se realiza un balanceo de clases mediante duplicación.\n",
    "\n",
    "1. **Carga del dataset**: \n",
    "   - Usamos `pandas.read_csv` para cargar los datos desde un archivo CSV (`wine_quality.csv`) y guardarlos en un DataFrame (`df`).\n",
    "\n",
    "2. **Distribución inicial de clases**:\n",
    "   - Mostramos la distribución de la variable objetivo `quality` antes de aplicar cualquier técnica de balanceo para observar el número de muestras por clase.\n",
    "\n",
    "3. **Duplicación de clases minoritarias**:\n",
    "   - Identificamos las clases que tienen menos de 10 registros (`min_registros = 10`).\n",
    "   - Para cada clase con pocos registros, duplicamos las filas de esa clase hasta alcanzar el mínimo de 10 registros.\n",
    "   - La duplicación se realiza de manera automática y se utiliza `pandas.concat` para agregar las filas repetidas al DataFrame original.\n",
    "\n",
    "4. **Distribución de clases después de duplicar**:\n",
    "   - Se recalcula y muestra la distribución de clases después de realizar la duplicación, permitiendo observar el efecto de esta estrategia de balanceo.\n",
    "\n",
    "Este proceso ayuda a asegurar que todas las clases tengan al menos un número mínimo de registros antes de entrenar los modelos, lo que puede mejorar la calidad de los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de valores por clase antes de duplicar:\n",
      "quality\n",
      "3      30\n",
      "4     216\n",
      "5    2138\n",
      "6    2836\n",
      "7    1079\n",
      "8     193\n",
      "9       5\n",
      "Name: count, dtype: int64\n",
      "Distribución de valores por clase después de duplicar:\n",
      "quality\n",
      "3      30\n",
      "4     216\n",
      "5    2138\n",
      "6    2836\n",
      "7    1079\n",
      "8     193\n",
      "9      15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset\n",
    "# Aquí reemplaza 'ruta_dataset.csv' con la ubicación de tu dataset\n",
    "ruta_dataset = 'wine_quality.csv'\n",
    "df = pd.read_csv(ruta_dataset)\n",
    "\n",
    "\n",
    "# Mostrar la distribución de valores inicial\n",
    "print(\"Distribución de valores por clase antes de duplicar:\")\n",
    "distribucion_clases = df['quality'].value_counts().sort_index()\n",
    "print(distribucion_clases)\n",
    "\n",
    "# Duplicar automáticamente clases con menos de 10 registros\n",
    "min_registros = 10\n",
    "for clase, conteo in distribucion_clases.items():\n",
    "    if conteo < min_registros:\n",
    "        # Filtrar las filas de la clase con pocos registros\n",
    "        df_clase = df[df['quality'] == clase]\n",
    "        # Calcular cuántas veces hay que duplicar para alcanzar el mínimo\n",
    "        veces_duplicar = (min_registros - conteo) // conteo + 1\n",
    "        # Duplicar y concatenar\n",
    "        df = pd.concat([df] + [df_clase] * veces_duplicar)\n",
    "\n",
    "# Recalcular y mostrar la distribución de valores actualizada\n",
    "print(\"Distribución de valores por clase después de duplicar:\")\n",
    "distribucion_clases_actualizada = df['quality'].value_counts().sort_index()\n",
    "print(distribucion_clases_actualizada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados de la carga y duplicación del dataset\n",
    "\n",
    "Tras cargar y procesar los datos, observamos lo siguiente:\n",
    "\n",
    "- **Distribución de valores por clase antes de duplicar**:\n",
    "  - La clase `9` tenía solo 5 registros, lo que es insuficiente para el modelado.\n",
    "  - Otras clases tienen una distribución bastante balanceada, con más registros en clases como `6` y `5`.\n",
    "\n",
    "- **Distribución de valores por clase después de duplicar**:\n",
    "  - Después de duplicar las clases con menos de 10 registros, la clase `9` se ha incrementado a 15 registros, alcanzando el mínimo de 10 establecido.\n",
    "  - Las demás clases no se vieron afectadas, ya que su número de registros ya era suficiente.\n",
    "\n",
    "Este proceso de duplicación ayuda a equilibrar las clases y garantizar que todas tengan suficientes ejemplos para entrenar modelos de clasificación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Aplicación de Label Encoding al target**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque se aplica el proceso de *Label Encoding* a la variable objetivo `quality`. El *Label Encoding* es una técnica de preprocesamiento que convierte las categorías de una columna en valores numéricos, lo cual es necesario para que los modelos de machine learning puedan trabajar con ellas.\n",
    "\n",
    "1. **Label Encoding**:\n",
    "   - Se utiliza `LabelEncoder` de `scikit-learn` para transformar la variable categórica `quality` en valores numéricos.\n",
    "   - La transformación asigna un número entero a cada clase de la variable `quality`, y el resultado se guarda en una nueva columna llamada `quality_encoded`.\n",
    "\n",
    "Este paso es crucial para convertir las etiquetas de clase (que inicialmente son valores como `3`, `4`, `5`, etc.) en un formato que los modelos puedan manejar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar Label Encoding al target\n",
    "label_encoder = LabelEncoder()\n",
    "df['quality_encoded'] = label_encoder.fit_transform(df['quality'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados de Label Encoding\n",
    "\n",
    "Después de aplicar *Label Encoding*, la columna `quality_encoded` contiene las representaciones numéricas de las clases en la columna `quality`. Por ejemplo, si la clase `3` fue codificada como `0`, `4` como `1`, y así sucesivamente.\n",
    "\n",
    "Este paso convierte las etiquetas en una forma numérica que los modelos de aprendizaje automático pueden usar, facilitando el proceso de entrenamiento y evaluación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Configuración de modelos**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este bloque se configuran los modelos de clasificación que se utilizarán en el análisis:\n",
    "\n",
    "1. **Random Forest**:\n",
    "   - Se crea una instancia del clasificador `RandomForestClassifier` con una semilla aleatoria para garantizar la reproducibilidad.\n",
    "\n",
    "2. **Gradient Boosting**:\n",
    "   - Se crea una instancia del clasificador `GradientBoostingClassifier`, también con la semilla aleatoria establecida para asegurar que los resultados sean consistentes.\n",
    "\n",
    "3. **XGBoost**:\n",
    "   - Se configuran dos opciones para `XGBoost`:\n",
    "     - La opción comentada con la línea original (`XGBClassifier`) en caso de que haya problemas con la versión de `XGBoost`.\n",
    "     - La opción activa usa `SklearnXGBClassifier`, que resuelve posibles incompatibilidades con `scikit-learn`.\n",
    "\n",
    "Estos clasificadores se usarán para entrenar el modelo y realizar predicciones sobre los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=SEED),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=SEED),\n",
    "    #\"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=SEED) # Si falla, usar esta linea\n",
    "    \"XGBoost\": SklearnXGBClassifier(eval_metric='logloss', random_state=SEED) # Si falla, usar esta linea\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Configuración de los parámetros para la búsqueda de hiperparámetros (Random Search)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque se definen los rangos de parámetros que se explorarán durante la búsqueda de hiperparámetros para cada uno de los modelos de clasificación.\n",
    "\n",
    "1. **Random Forest** (`param_distributions_rf`):\n",
    "   - **`n_estimators`**: Número de árboles en el bosque (50, 100, 150).\n",
    "   - **`max_depth`**: Profundidad máxima de los árboles para controlar el sobreajuste (10, 15, 20).\n",
    "   - **`min_samples_split`**: Número mínimo de muestras necesarias para dividir un nodo (2, 4, 8).\n",
    "   - **`min_samples_leaf`**: Número mínimo de muestras necesarias para estar en una hoja (1, 2).\n",
    "\n",
    "2. **Gradient Boosting** (`param_distributions_gb`):\n",
    "   - **`n_estimators`**: Número de estimadores (50, 100, 150).\n",
    "   - **`learning_rate`**: Tasa de aprendizaje para el ajuste de los árboles (0.1, 0.05, 0.01).\n",
    "   - **`max_depth`**: Profundidad máxima de cada árbol en el modelo boosting (3, 4, 5).\n",
    "   - **`subsample`**: Proporción de muestras utilizadas para entrenar cada árbol (0.8, 1.0).\n",
    "\n",
    "3. **XGBoost** (`param_distributions_xgb`):\n",
    "   - **`n_estimators`**: Número de estimadores (50, 100, 150).\n",
    "   - **`learning_rate`**: Tasa de aprendizaje (0.1, 0.05, 0.01).\n",
    "   - **`max_depth`**: Profundidad máxima de los árboles (3, 4, 5).\n",
    "   - **`subsample`**: Proporción de muestras utilizadas por árbol (0.8, 1.0).\n",
    "   - **`colsample_bytree`**: Proporción de características usadas por cada árbol (0.7, 1.0).\n",
    "   - **`lambda`**: Regularización L2 (1, 10).\n",
    "   - **`alpha`**: Regularización L1 (0.1, 1).\n",
    "\n",
    "Estos parámetros se utilizarán en la búsqueda de hiperparámetros para optimizar el rendimiento de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions_rf = {\n",
    "    \"n_estimators\": [50, 100, 150],  # Reducimos el rango pero mantenemos opciones razonables\n",
    "    \"max_depth\": [10, 15, 20],      # Limitar a profundidades clave\n",
    "    \"min_samples_split\": [2, 4, 8], # Opciones comunes para reducir overfitting\n",
    "    \"min_samples_leaf\": [1, 2],     # Añadimos este parámetro porque puede impactar en datasets pequeños\n",
    "}\n",
    "\n",
    "\n",
    "param_distributions_gb = {\n",
    "    \"n_estimators\": [50, 100, 150],       # Valores que evitan sobreentrenar rápidamente\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],  # Rango más pequeño pero suficiente para explorar ajustes\n",
    "    \"max_depth\": [3, 4, 5],              # Valores típicos en boosting\n",
    "    \"subsample\": [0.8, 1.0],             # Control de muestra para evitar overfitting\n",
    "}\n",
    "\n",
    "\n",
    "param_distributions_xgb = {\n",
    "    \"n_estimators\": [50, 100, 150],          # Reducido a valores prácticos\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],     # Similares a Gradient Boosting\n",
    "    \"max_depth\": [3, 4, 5],                 # Foco en valores eficientes\n",
    "    \"subsample\": [0.8, 1.0],                # Fracción de datos a usar por iteración\n",
    "    \"colsample_bytree\": [0.7, 1.0],         # Número de características por árbol\n",
    "    \"lambda\": [1, 10],                      # Regularización L2 básica\n",
    "    \"alpha\": [0.1, 1],                      # Regularización L1 para sparsity\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Configuración de los parámetros para la búsqueda de hiperparámetros (Grid Search)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En este bloque se definen los parámetros de búsqueda que se utilizarán en la función de `GridSearchCV` para cada modelo, especificando los rangos de valores para optimizar durante la búsqueda.\n",
    "\n",
    "1. **Random Forest** (`param_grids[\"Random Forest\"]`):\n",
    "   - **`n_estimators`**: Número de árboles en el bosque (100, 200).\n",
    "   - **`max_depth`**: Profundidad máxima de los árboles (ninguna o 10).\n",
    "   - **`min_samples_split`**: Número mínimo de muestras necesarias para dividir un nodo (2, 5).\n",
    "   - **`min_samples_leaf`**: Número mínimo de muestras necesarias para estar en una hoja (1, 2).\n",
    "\n",
    "2. **Gradient Boosting** (`param_grids[\"Gradient Boosting\"]`):\n",
    "   - **`n_estimators`**: Número de iteraciones (100, 200).\n",
    "   - **`learning_rate`**: Tasa de aprendizaje para ajustar la influencia de cada árbol (0.01, 0.1).\n",
    "   - **`max_depth`**: Profundidad máxima de los árboles (3, 5).\n",
    "\n",
    "3. **XGBoost** (`param_grids[\"XGBoost\"]`):\n",
    "   - **`n_estimators`**: Número de iteraciones (100, 200).\n",
    "   - **`learning_rate`**: Tasa de aprendizaje (0.05, 0.1).\n",
    "   - **`max_depth`**: Profundidad máxima de los árboles (3, 5).\n",
    "   - **`gamma`**: Penalización por la complejidad del modelo (0, 1).\n",
    "   - **`lambda`**: Regularización L2 (1).\n",
    "   - **`alpha`**: Regularización L1 (0.1, 1.0).\n",
    "\n",
    "Estos parámetros serán utilizados en la búsqueda de hiperparámetros mediante `GridSearchCV` para encontrar la combinación óptima que maximice el rendimiento del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de grids\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "    \"n_estimators\": [100, 200],             # Solo 2 valores para el número de árboles\n",
    "    \"max_depth\": [None, 10],               # Profundidad máxima\n",
    "    \"min_samples_split\": [2, 5],           # División mínima\n",
    "    \"min_samples_leaf\": [1, 2]             # Número mínimo de muestras por hoja\n",
    "},\n",
    "\n",
    "    \"Gradient Boosting\": {\n",
    "    \"n_estimators\": [100, 200],            # Número de iteraciones\n",
    "    \"learning_rate\": [0.01, 0.1],          # Tasas de aprendizaje más comunes\n",
    "    \"max_depth\": [3, 5]                    # Profundidad máxima                 \n",
    "},\n",
    "\n",
    "   \"XGBoost\": {\n",
    "    \"n_estimators\": [100, 200],            # Número de iteraciones\n",
    "    \"learning_rate\": [0.05, 0.1],          # Tasas de aprendizaje\n",
    "    \"max_depth\": [3, 5],                   # Profundidad máxima\n",
    "    \"gamma\": [0, 1],                       # Penalización por nodos adicionales\n",
    "    \"lambda\": [1],                         # Regularización L2 (valor fijo razonable)\n",
    "    \"alpha\": [0.1, 1.0]                    # Regularización L1\n",
    "}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construccion del pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del Pipeline\n",
    "\n",
    "En este bloque se construye el *pipeline* para el preprocesamiento de los datos antes de entrenar el modelo. El *pipeline* permite encadenar múltiples pasos de procesamiento y aplicar las transformaciones de manera secuencial.\n",
    "\n",
    "1. **Paso 1: Eliminar Duplicados** (comentado):\n",
    "   - Se ha desactivado esta parte del *pipeline* ya que su aplicación empeoraba el rendimiento del modelo. Sin embargo, esta fase podría ser útil en otros escenarios donde los duplicados sean problemáticos.\n",
    "\n",
    "2. **Paso 2: Tratamiento de Outliers**:\n",
    "   - Se utiliza la clase `HandleOutliers`, que maneja los valores atípicos mediante la aplicación de un límite superior a la columna `density` y la eliminación de outliers en `total_sulfur_dioxide` usando el rango intercuartílico (IQR).\n",
    "   - Este paso ayuda a prevenir que los outliers distorsionen el entrenamiento del modelo.\n",
    "   - Se puede activar o desactivar este paso cambiando active=True por False\n",
    "\n",
    "3. **Paso 3: Transformación de Características**:\n",
    "   - Se usa la clase `FeatureTransformations` para realizar transformaciones específicas en varias columnas del dataset, como la aplicación de logaritmos y Box-Cox, así como la estandarización de `citric_acid`.\n",
    "   - Estas transformaciones pueden mejorar la capacidad del modelo para aprender patrones relevantes.\n",
    "\n",
    "4. **Paso 4: Combinación de Características** (comentado):\n",
    "   - Se ha desactivado esta fase debido a que perjudicaba el análisis, pero la clase `FeatureCombinations` permite crear nuevas variables combinando las existentes, lo que puede mejorar el rendimiento del modelo en algunos casos.\n",
    "\n",
    "Este *pipeline* se asegura de que las transformaciones y manipulaciones de los datos se realicen de manera coherente y eficiente antes de entrenar el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    #('Paso 1: Eliminar Duplicados', RemoveDuplicates()),  # Desactivado - Empeora el resultado\n",
    "    ('Paso 2: Tratamiento Outliers', HandleOutliers(active=False, density_cap=1.05)),  # Paso 2: manejar outliers\n",
    "    ('Paso 3: Transformación de características', FeatureTransformations(scale=False)),  # Paso 3: transformaciones específicas\n",
    "    #('Paso 4: Combinación de características', FeatureCombinations()),  # Paso 5: combinaciones de variables\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Aplicación del Pipeline**\n",
    "\n",
    "En este bloque, aplicamos el *pipeline* que hemos construido previamente al conjunto de datos `df`. La función `fit_transform()` se utiliza para ajustar y transformar el dataset en un solo paso.\n",
    "\n",
    "1. **`fit_transform(df)`**:\n",
    "   - El método `fit_transform()` realiza dos tareas:\n",
    "     - **Fit**: Ajusta todos los pasos del *pipeline* a los datos de entrada (`df`), es decir, calcula las estadísticas necesarias para las transformaciones (por ejemplo, para la estandarización o la detección de outliers).\n",
    "     - **Transform**: Aplica las transformaciones calculadas durante el ajuste a los datos, devolviendo el dataset procesado.\n",
    "   \n",
    "2. **Resultado**:\n",
    "   - El resultado es el DataFrame `df_procesado`, que contiene los datos después de haber pasado por todos los pasos definidos en el *pipeline* (manejo de outliers y transformaciones de características).\n",
    "\n",
    "Este paso prepara los datos para ser utilizados en el entrenamiento de los modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos el pipeline\n",
    "df_procesado = pipeline.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados esperados\n",
    "\n",
    "Tras aplicar el *pipeline* con `fit_transform()`, obtenemos el DataFrame `df_procesado`, que contiene las siguientes transformaciones:\n",
    "  \n",
    "- Los outliers han sido manejados según los parámetros establecidos.\n",
    "- Las características han sido transformadas, incluyendo logaritmos, Box-Cox y estandarización, según corresponda.\n",
    "\n",
    "Este conjunto de datos procesado está listo para ser utilizado en el entrenamiento de modelos de machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **División del Dataset en Entrenamiento y Prueba**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En este bloque se divide el dataset procesado en dos conjuntos: uno para entrenar los modelos y otro para evaluarlos. Usamos la función `train_test_split` de `scikit-learn` para realizar esta partición.\n",
    "\n",
    "1. **Definición de variables**:\n",
    "   - **`X`**: Contiene las características del dataset, excluyendo las columnas `quality_encoded` y `quality`, que son la variable objetivo.\n",
    "   - **`y`**: Contiene la variable objetivo, que es la columna `quality_encoded`, que ya ha sido codificada numéricamente.\n",
    "\n",
    "2. **División en conjunto de entrenamiento y prueba**:\n",
    "   - Usamos `train_test_split(X, y, test_size=0.2, random_state=SEED)` para dividir los datos en un 80% para entrenamiento y un 20% para prueba. Esto garantiza que el modelo se entrene con una gran parte de los datos y se evalúe con un conjunto independiente para comprobar su rendimiento.\n",
    "   - **`random_state=SEED`** asegura que la división sea reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos en entrenamiento y prueba\n",
    "X = df_procesado.drop(['quality_encoded','quality'], axis=1)  \n",
    "y = df_procesado['quality_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados esperados\n",
    "\n",
    "Este bloque no genera resultados inmediatos, pero la división de los datos crea cuatro variables:\n",
    "- **`X_train`**: Conjunto de entrenamiento con las características.\n",
    "- **`X_test`**: Conjunto de prueba con las características.\n",
    "- **`y_train`**: Conjunto de entrenamiento con la variable objetivo.\n",
    "- **`y_test`**: Conjunto de prueba con la variable objetivo.\n",
    "\n",
    "Estas variables se usarán para entrenar los modelos y luego evaluar su rendimiento en el conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prueba de Modelos con Búsqueda de Hiperparámetros**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque, se entrenan y evalúan los modelos utilizando **Grid Search** o **Random Search** para encontrar la mejor combinación de hiperparámetros. La elección de la búsqueda se define en la variable `search_method`.\n",
    "\n",
    "Ene esta parte se introducen todas las variables a los modelo.\n",
    "\n",
    "1. **Configuración de búsqueda**:\n",
    "   - Se prueba cada modelo con diferentes estrategias de balanceo de clases (`balance`, `ninguno`).\n",
    "   - Dependiendo de la elección de `search_method`, se utiliza:\n",
    "     - **Grid Search** (`GridSearchCV`): Realiza una búsqueda exhaustiva de todos los parámetros definidos en `param_grids`.\n",
    "     - **Random Search** (`RandomizedSearchCV`): Realiza una búsqueda aleatoria sobre los parámetros definidos en `param_distributions` para cada modelo.\n",
    "\n",
    "2. **Proceso de evaluación**:\n",
    "   - Para cada modelo, se ajustan los hiperparámetros usando las funciones `probar_modelo_con_grid` o `probar_modelo_con_random_search`, y se evalúan con la métrica `F1-Weighted`.\n",
    "   - Los resultados, que incluyen el rendimiento del modelo y los mejores hiperparámetros, se almacenan en la lista `resultados`.\n",
    "\n",
    "3. **Selección del mejor modelo**:\n",
    "   - Al final del proceso, el modelo con el mejor `F1-Weighted` se identifica y se guarda como el modelo ganador.\n",
    "   - El modelo ganador es el que tiene la mejor puntuación en el conjunto de datos de prueba, considerando los hiperparámetros óptimos encontrados.\n",
    "\n",
    "Este bloque permite encontrar el modelo más adecuado para el conjunto de datos a través de la optimización de hiperparámetros, ayudando a mejorar el rendimiento general del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo ganador es: Random Forest\n",
      "El modelo ganador es: Random Forest\n",
      "El modelo ganador es: Random Forest\n",
      "El modelo ganador es: Random Forest\n",
      "El modelo ganador es: Random Forest\n",
      "El modelo ganador es: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# Resultados\n",
    "resultados = []\n",
    "\n",
    "# Modos a probar (oversampling, balance, ninguno)\n",
    "modos = [\"balance\", \"ninguno\"]\n",
    "\n",
    "search_method = \"Random Search\"  # Puedes cambiar a \"Grid Search\" si prefieres\n",
    "\n",
    "if search_method == \"Grid Search\":\n",
    "    print(\"Usando Grid Search...\")\n",
    "\n",
    "    # Probar cada modelo con Grid Search\n",
    "    for nombre, modelo in modelos.items():\n",
    "        param_grid = param_grids[nombre]  # Obtenemos el grid correspondiente\n",
    "        for modo in modos:\n",
    "            f1, best_params, best_model = probar_modelo_con_grid(\n",
    "                modelo,\n",
    "                X_train,\n",
    "                y_train,\n",
    "                X_test,\n",
    "                y_test,\n",
    "                param_grid=param_grid,\n",
    "                modo=modo\n",
    "            )\n",
    "            resultados.append({\n",
    "                \"Modelo\": nombre,\n",
    "                \"Modo\": modo,\n",
    "                \"F1-Weighted\": f1,\n",
    "                \"Mejores Hiperparámetros\": best_params\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "    # Identificar el modelo con mejor F1-Weighted\n",
    "    mejor_modelo = max(resultados, key=lambda x: x['F1-Weighted'])\n",
    "    nombre_modelo_ganador = mejor_modelo['Modelo']\n",
    "\n",
    "    print(f\"El modelo ganador es: {nombre_modelo_ganador}\")\n",
    "    # Guardamos el modelo ajustado\n",
    "    modelos[nombre] = best_model\n",
    "\n",
    "\n",
    "if search_method == \"Random Search\":\n",
    "\n",
    "    # Probar cada modelo con Random Search\n",
    "    for nombre, modelo in modelos.items():\n",
    "        if nombre == \"Random Forest\":\n",
    "            param_distributions = param_distributions_rf\n",
    "        elif nombre == \"XGBoost\":\n",
    "            param_distributions = param_distributions_xgb\n",
    "        elif nombre == \"Gradient Boosting\":\n",
    "            param_distributions = param_distributions_gb\n",
    "        else:\n",
    "            raise ValueError(f\"Modelo no reconocido: {nombre}\")\n",
    "        \n",
    "        for modo in modos:\n",
    "            f1, best_params, best_model = probar_modelo_con_random_search(\n",
    "                modelo,\n",
    "                X_train,\n",
    "                y_train,\n",
    "                X_test,\n",
    "                y_test,\n",
    "                param_distributions=param_distributions,\n",
    "                n_iter=50,  # Ajustable según los recursos\n",
    "                modo=modo\n",
    "            )\n",
    "            resultados.append({\n",
    "                \"Modelo\": nombre,\n",
    "                \"Modo\": modo,\n",
    "                \"F1-Weighted\": f1,\n",
    "                \"Mejores Hiperparámetros\": best_params\n",
    "            })\n",
    "\n",
    "            # Identificar el modelo con mejor F1-Weighted\n",
    "            mejor_modelo = max(resultados, key=lambda x: x['F1-Weighted'])\n",
    "            nombre_modelo_ganador = mejor_modelo['Modelo']\n",
    "\n",
    "            print(f\"El modelo ganador es: {nombre_modelo_ganador}\")\n",
    "            # Guardamos el modelo ajustado\n",
    "            modelos[nombre] = best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Entrenamiento y Evaluación del Modelo Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque se entrena y evalúa un modelo de referencia (*baseline*), sin aplicar las transformaciones del *pipeline*. Este modelo se utiliza para comparar el rendimiento de los modelos más avanzados que se probarán más tarde.\n",
    "\n",
    "1. **Dataset para el Baseline**:\n",
    "   - Se excluyen las columnas `quality` y `quality_encoded` para definir las características (`X_baseline`) y se utiliza la columna `quality_encoded` como la variable objetivo (`y_baseline`).\n",
    "   \n",
    "2. **División en conjunto de entrenamiento y prueba**:\n",
    "   - Se divide el dataset en conjuntos de entrenamiento y prueba, usando un 80% para entrenamiento y un 20% para prueba. Esto se hace utilizando `train_test_split`, con la misma semilla para garantizar la reproducibilidad.\n",
    "\n",
    "3. **Entrenamiento del modelo Baseline**:\n",
    "   - Se entrena un modelo `XGBClassifier` sin utilizar *GridSearch* ni *RandomSearch*, con los parámetros predeterminados. El modelo es entrenado en el conjunto de entrenamiento (`X_train_base` y `y_train_base`).\n",
    "\n",
    "4. **Evaluación del Baseline**:\n",
    "   - Se realiza una predicción sobre el conjunto de prueba (`X_test_base`), y se calcula el `F1-Weighted`, que es la métrica utilizada para evaluar el rendimiento del modelo, considerando el balance entre precisión y recall en clases desbalanceadas.\n",
    "\n",
    "5. **Registro de resultados**:\n",
    "   - Los resultados de este modelo baseline, incluyendo la puntuación `F1-Weighted` y la indicación de que no se usó búsqueda de hiperparámetros, se añaden a la lista `resultados` para su comparación posterior con los otros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:05:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Dataset para el baseline (sin pasar por el pipeline)\n",
    "X_baseline = df.drop(['quality', 'quality_encoded'], axis=1)\n",
    "y_baseline = df['quality_encoded']\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(\n",
    "    X_baseline, y_baseline, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "# Entrenar y evaluar el baseline\n",
    "baseline_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=SEED)\n",
    "baseline_model.fit(X_train_base, y_train_base)\n",
    "y_pred_base = baseline_model.predict(X_test_base)\n",
    "\n",
    "# Calcular F1-Weighted\n",
    "f1_baseline = f1_score(y_test_base, y_pred_base, average='weighted')\n",
    "\n",
    "# Añadir a resultados\n",
    "resultados.append({\n",
    "    \"Modelo\": \"Baseline XGBoost\",\n",
    "    \"Modo\": \"Ninguno\",\n",
    "    \"F1-Weighted\": f1_baseline,\n",
    "    \"Mejores Hiperparámetros\": \"Sin GridSearch\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados esperados\n",
    "\n",
    "Este bloque calculará los siguientes resultados:\n",
    "\n",
    "- **F1-Weighted**: El rendimiento del modelo baseline, que se espera que sirva como referencia para los modelos posteriores. \n",
    "- **Mejores Hiperparámetros**: En este caso, no se utilizaron búsquedas de hiperparámetros, por lo que el valor será \"Sin GridSearch\".\n",
    "\n",
    "El modelo baseline proporciona un punto de partida para comparar los modelos que se optimizarán en los siguientes pasos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluación de Modelos y Visualización de Resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En este bloque se organizan y muestran los resultados obtenidos de la prueba de los modelos. La métrica clave es el `F1-Weighted`, que evalúa el rendimiento de cada modelo considerando el balance entre precisión y recall.\n",
    "\n",
    "1. **Creación de un DataFrame con los resultados**:\n",
    "   - Se convierte la lista `resultados` en un DataFrame de `pandas` para facilitar la visualización.\n",
    "   - El DataFrame contiene los resultados de los modelos probados, con las columnas: `Modelo`, `Modo`, `F1-Weighted`, y `Mejores Hiperparámetros`.\n",
    "\n",
    "2. **Ordenación por `F1-Weighted`**:\n",
    "   - Se ordenan los resultados por la puntuación `F1-Weighted` de manera descendente, de modo que el mejor modelo aparezca en la parte superior.\n",
    "\n",
    "3. **Configuración de opciones de visualización**:\n",
    "   - Se ajustan varias opciones de `pandas` para mostrar todas las filas, columnas, y datos sin que se corten, lo que permite ver todos los resultados en detalle.\n",
    "\n",
    "4. **Mostrar los resultados**:\n",
    "   - Finalmente, se muestra el DataFrame con todos los resultados utilizando `display(resultados_df)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Modo</th>\n",
       "      <th>F1-Weighted</th>\n",
       "      <th>Mejores Hiperparámetros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.687034</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.681682</td>\n",
       "      <td>{'n_estimators': 150, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline XGBoost</td>\n",
       "      <td>Ninguno</td>\n",
       "      <td>0.666304</td>\n",
       "      <td>Sin GridSearch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.658129</td>\n",
       "      <td>{'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.641995</td>\n",
       "      <td>{'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.603245</td>\n",
       "      <td>{'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 10, 'colsample_bytree': 0.7, 'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.555762</td>\n",
       "      <td>{'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 10, 'colsample_bytree': 0.7, 'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Modelo     Modo  F1-Weighted                                                                                                             Mejores Hiperparámetros\n",
       "0      Random Forest  balance     0.687034                                               {'n_estimators': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20}\n",
       "1      Random Forest  ninguno     0.681682                                               {'n_estimators': 150, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20}\n",
       "2   Baseline XGBoost  Ninguno     0.666304                                                                                                                      Sin GridSearch\n",
       "3  Gradient Boosting  ninguno     0.658129                                                       {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1}\n",
       "4  Gradient Boosting  balance     0.641995                                                       {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1}\n",
       "5            XGBoost  ninguno     0.603245  {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 10, 'colsample_bytree': 0.7, 'alpha': 0.1}\n",
       "6            XGBoost  balance     0.555762  {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 10, 'colsample_bytree': 0.7, 'alpha': 0.1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostrar resultados ordenados por f1-weighted\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "resultados_df = resultados_df.sort_values(by='F1-Weighted', ascending=False)\n",
    "resultados_df = resultados_df.reset_index(drop=True)\n",
    "# Mostrar todas las filas\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# Mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Mostrar todas las columnas\n",
    "pd.set_option('display.width', None)\n",
    "# Mostrar todos los resultados\n",
    "pd.set_option('display.max_rows', None)\n",
    "# Evitar que las columnas se corten\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "display(resultados_df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones de los Resultados\n",
    "\n",
    "Tras la evaluación de los modelos, se pueden extraer las siguientes conclusiones basadas en la métrica `F1-Weighted`:\n",
    "\n",
    "1. **Modelo con Mejor Rendimiento**:\n",
    "   - El **Random Forest** con estrategia de balanceo (`balance`) alcanzó el mejor rendimiento con un `F1-Weighted` de **0.687034**. Este resultado indica que el balanceo de clases mejora la capacidad del modelo para manejar desequilibrios en los datos.\n",
    "\n",
    "2. **Comparación del Random Forest**:\n",
    "   - El Random Forest sin balanceo (`ninguno`) obtuvo un puntaje ligeramente inferior de **0.681682**, mostrando que el balanceo de clases aporta una mejora significativa en el rendimiento.\n",
    "\n",
    "3. **Baseline XGBoost**:\n",
    "   - El modelo de línea base (**Baseline XGBoost**) sin optimización de hiperparámetros alcanzó un `F1-Weighted` de **0.666304**, posicionándose en el tercer lugar. Este resultado sirve como referencia inicial para comparar otros modelos.\n",
    "\n",
    "4. **Gradient Boosting**:\n",
    "   - El Gradient Boosting con estrategia sin balanceo (`ninguno`) obtuvo un `F1-Weighted` de **0.658129**, superando al mismo modelo con balanceo (`balance`), que logró **0.641995**. Esto sugiere que el balanceo no siempre mejora el rendimiento para este modelo.\n",
    "\n",
    "5. **XGBoost con Optimización**:\n",
    "   - Los modelos XGBoost con búsqueda de hiperparámetros no superaron el rendimiento del baseline, incluso después de aplicar balanceo. El mejor resultado fue **0.603245** sin balanceo, indicando que la configuración inicial del baseline puede ser más adecuada para este conjunto de datos.\n",
    "\n",
    "6. **Impacto del Balanceo de Clases**:\n",
    "   - Aunque el balanceo de clases mejora algunos modelos (como el Random Forest), no es una solución universal. En el caso de Gradient Boosting y XGBoost, esta técnica no aportó beneficios claros.\n",
    "\n",
    "\n",
    "### Resultados Destacados\n",
    "\n",
    "| Modelo             | Modo     | F1-Weighted | Mejores Hiperparámetros                                                               |\n",
    "|--------------------|----------|-------------|---------------------------------------------------------------------------------------|\n",
    "| Random Forest      | balance  | 0.687034    | {'n_estimators': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20} |\n",
    "| Random Forest      | ninguno  | 0.681682    | {'n_estimators': 150, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20} |\n",
    "| Baseline XGBoost   | Ninguno  | 0.666304    | Sin GridSearch                                                                        |\n",
    "| Gradient Boosting  | ninguno  | 0.658129    | {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1}         |\n",
    "| Gradient Boosting  | balance  | 0.641995    | {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1}         |\n",
    "| XGBoost            | ninguno  | 0.603245    | {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 10, 'colsample_bytree': 0.7, 'alpha': 0.1} |\n",
    "| XGBoost            | balance  | 0.555762    | {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 10, 'colsample_bytree': 0.7, 'alpha': 0.1} |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cálculo y Visualización de la Importancia de Características**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En este bloque, se extraen y visualizan las importancias de las características (atributos) del modelo ganador, lo que nos permite entender qué variables son más relevantes para las predicciones del modelo.\n",
    "\n",
    "1. **Extracción de la importancia de características**:\n",
    "   - Dependiendo del modelo ganador (ya sea **Random Forest**, **Gradient Boosting**, o **XGBoost**), se extraen las importancias de las características utilizando el atributo `feature_importances_` del modelo.\n",
    "   - Estas importancias indican cuán relevante es cada característica para la predicción del modelo.\n",
    "\n",
    "2. **Verificación de longitudes**:\n",
    "   - Se verifica que el número de características coincida con el número de importancias. Si hay un desajuste, se lanza un error.\n",
    "   \n",
    "3. **Creación del DataFrame de importancias**:\n",
    "   - Se crea un DataFrame donde cada fila contiene el nombre de la característica y su correspondiente importancia.\n",
    "   - El DataFrame se ordena de mayor a menor según la importancia, para facilitar la interpretación.\n",
    "\n",
    "4. **Mostrar las importancias**:\n",
    "   - Finalmente, se muestra el DataFrame con las importancias de las características.\n",
    "\n",
    "Este paso es útil para identificar qué características son más influyentes en la predicción del modelo y puede ser clave para la interpretación del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>0.129675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volatile_acidity</td>\n",
       "      <td>0.103642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>density</td>\n",
       "      <td>0.101123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total_sulfur_dioxide</td>\n",
       "      <td>0.089404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chlorides</td>\n",
       "      <td>0.085959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>free_sulfur_dioxide</td>\n",
       "      <td>0.085462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sulphates</td>\n",
       "      <td>0.084537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>residual_sugar</td>\n",
       "      <td>0.084505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pH</td>\n",
       "      <td>0.083123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>citric_acid</td>\n",
       "      <td>0.079084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed_acidity</td>\n",
       "      <td>0.073486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature  Importance\n",
       "10               alcohol    0.129675\n",
       "1       volatile_acidity    0.103642\n",
       "7                density    0.101123\n",
       "6   total_sulfur_dioxide    0.089404\n",
       "4              chlorides    0.085959\n",
       "5    free_sulfur_dioxide    0.085462\n",
       "9              sulphates    0.084537\n",
       "3         residual_sugar    0.084505\n",
       "8                     pH    0.083123\n",
       "2            citric_acid    0.079084\n",
       "0          fixed_acidity    0.073486"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extraer las importancias de las características\n",
    "if nombre_modelo_ganador == \"Random Forest\":\n",
    "    importancias = modelos[\"Random Forest\"].feature_importances_\n",
    "elif nombre_modelo_ganador == \"Gradient Boosting\":\n",
    "    importancias = modelos[\"Gradient Boosting\"].feature_importances_\n",
    "elif nombre_modelo_ganador == \"XGBoost\":\n",
    "    importancias = modelos[\"XGBoost\"].feature_importances_\n",
    "else:\n",
    "    raise ValueError(f\"No se puede calcular la importancia para el modelo: {nombre_modelo_ganador}\")\n",
    "\n",
    "# Verificar longitudes\n",
    "if len(X_train.columns) != len(importancias):\n",
    "    print(f\"Longitud de X_train.columns: {len(X_train.columns)}\")\n",
    "    print(f\"Longitud de importancias: {len(importancias)}\")\n",
    "    raise ValueError(\"Las longitudes de las columnas y las importancias no coinciden.\")\n",
    "\n",
    "# Crear un dataframe con las importancias\n",
    "importancias_df = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": importancias\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Mostrar las importancias\n",
    "display(importancias_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones de las Importancias de las Características\n",
    "\n",
    "Tras el análisis de las importancias de las características para el modelo ganador (**Random Forest**), se pueden extraer las siguientes conclusiones:\n",
    "\n",
    "1. **Características Más Relevantes**:\n",
    "   - La característica con mayor importancia es **alcohol** con un valor de **0.129675**, lo que indica que tiene el mayor peso en las predicciones del modelo.\n",
    "   - Otras características destacadas incluyen:\n",
    "     - **volatile_acidity** (0.103642)\n",
    "     - **density** (0.101123)\n",
    "     - **total_sulfur_dioxide** (0.089404)\n",
    "\n",
    "2. **Influencia de las Variables**:\n",
    "   - Las características relacionadas con la composición química del vino, como **chlorides**, **sulphates**, y **pH**, tienen una importancia significativa. Esto sugiere que las propiedades físico-químicas son determinantes para la calidad del vino en el modelo.\n",
    "\n",
    "3. **Distribución de Importancias**:\n",
    "   - Aunque hay una diferencia notable entre la característica más importante (**alcohol**) y la menos importante (**fixed_acidity** con 0.073486), la distribución general de importancias es relativamente equilibrada, lo que refleja que múltiples variables contribuyen al modelo.\n",
    "\n",
    "4. **Aplicaciones Prácticas**:\n",
    "   - Este análisis permite identificar variables clave que podrían priorizarse en futuros experimentos o ajustes del modelo.\n",
    "   - Por ejemplo, aumentar la calidad de los datos para las variables más influyentes, como **alcohol** o **volatile_acidity**, podría mejorar aún más el rendimiento del modelo.\n",
    "\n",
    "### Resultados Destacados\n",
    "\n",
    "| Feature              | Importance  |\n",
    "|----------------------|-------------|\n",
    "| alcohol              | 0.129675    |\n",
    "| volatile_acidity     | 0.103642    |\n",
    "| density              | 0.101123    |\n",
    "| total_sulfur_dioxide | 0.089404    |\n",
    "| chlorides            | 0.085959    |\n",
    "| free_sulfur_dioxide  | 0.085462    |\n",
    "| sulphates            | 0.084537    |\n",
    "| residual_sugar       | 0.084505    |\n",
    "| pH                   | 0.083123    |\n",
    "| citric_acid          | 0.079084    |\n",
    "| fixed_acidity        | 0.073486    |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualización de la Importancia de Características**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque, se grafica la importancia de las características utilizando un gráfico de barras horizontal. Este gráfico facilita la interpretación visual de qué variables son más relevantes en el modelo.\n",
    "\n",
    "1. **Creación del gráfico de barras**:\n",
    "   - Utilizamos `matplotlib` para crear un gráfico de barras horizontal.\n",
    "   - El eje `x` representa la importancia de las características, mientras que el eje `y` muestra las características ordenadas de mayor a menor importancia.\n",
    "\n",
    "2. **Personalización del gráfico**:\n",
    "   - Se ajusta el tamaño del gráfico para mejorar la visualización.\n",
    "   - Se añaden etiquetas a los ejes y un título que describe lo que se está mostrando.\n",
    "   - Se invierte el eje `y` para que la característica con mayor importancia aparezca en la parte superior del gráfico.\n",
    "\n",
    "3. **Mostrar el gráfico**:\n",
    "   - Finalmente, el gráfico se muestra usando `plt.show()`.\n",
    "\n",
    "Este gráfico permite una rápida identificación visual de las características más importantes, ayudando en la interpretación y comprensión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar las importancias\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importancias_df[\"Feature\"], importancias_df[\"Importance\"], color=\"skyblue\")\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Características\")\n",
    "plt.title(\"Importancia de las Características\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones del Gráfico de Importancia de las Características\n",
    "\n",
    "El gráfico de barras horizontal proporciona una interpretación visual clara de las importancias de las características, destacando las siguientes conclusiones:\n",
    "\n",
    "1. **Características Más Influyentes**:\n",
    "   - **alcohol** es la característica más importante, lo que confirma su relevancia en las predicciones del modelo. Su barra más larga resalta su gran peso en comparación con el resto.\n",
    "   - **volatile_acidity** y **density** también destacan con barras significativamente largas, lo que refuerza su relevancia en el modelo.\n",
    "\n",
    "2. **Distribución Visual**:\n",
    "   - El gráfico muestra que las importancias están relativamente distribuidas, pero con un gradiente claro desde **alcohol** hasta **fixed_acidity**.\n",
    "   - Las diferencias en la longitud de las barras reflejan las contribuciones individuales de cada característica al modelo.\n",
    "\n",
    "3. **Aplicaciones Prácticas**:\n",
    "   - Este gráfico permite identificar visualmente las variables clave que deberían ser priorizadas en la recopilación y limpieza de datos.\n",
    "   - Las variables menos importantes, como **fixed_acidity**, podrían ser menos relevantes para optimizar o interpretar.\n",
    "\n",
    "El uso de esta representación gráfica facilita la comprensión de cómo el modelo utiliza las variables para realizar predicciones, ayudando a los usuarios a enfocar esfuerzos en las características más relevantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Selección de Características y Evaluación de Modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque se realiza la selección de características y se evalúan los modelos utilizando los conjuntos de datos filtrados. La selección de características se puede hacer de manera automática, utilizando un umbral de importancia, o de manera manual, eligiendo directamente las características relevantes.\n",
    "\n",
    "1. **Modos a probar**:\n",
    "   - Se prueban tres modos: **oversampling**, **balance**, y **ninguno**. En este caso, se han excluido los resultados de oversampling debido a que generaron malos resultados en etapas anteriores.\n",
    "\n",
    "2. **Selección de características**:\n",
    "   - **Automática**: Se seleccionan las características cuya importancia es mayor que un umbral (`umbral_importancia = 0.08`). Este valor puede ajustarse según los resultados del gráfico de importancias.\n",
    "   - **Manual**: Si se prefiere una selección de características personalizada, se puede especificar una lista de características manualmente en la variable `manual_features`.\n",
    "\n",
    "3. **Entrenamiento y evaluación**:\n",
    "   - Para cada modelo, se entrena y evalúa con las características seleccionadas, utilizando las combinaciones de parámetros definidas en los grids de búsqueda.\n",
    "   - Se evalúan con el modo de balanceo seleccionado (balance, ninguno).\n",
    "\n",
    "4. **Selección del mejor modelo**:\n",
    "   - Al final del proceso, se selecciona el modelo con el mejor `F1-Weighted` para determinar el modelo ganador.\n",
    "\n",
    "Este paso permite evaluar los modelos con diferentes conjuntos de características, comparando su rendimiento bajo distintas estrategias de selección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 16 is smaller than n_iter=50. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 16 is smaller than n_iter=50. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=50. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=50. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 32 is smaller than n_iter=50. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 32 is smaller than n_iter=50. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo ganador es: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# Modos a probar: oversampling, balance y sin modificaciones (Oversampling da malos resultados)\n",
    "modos = [\"balance\", \"ninguno\"]\n",
    "\n",
    "# Umbral para selección automática (puedes ajustarlo según el gráfico de importancia)\n",
    "umbral_importancia = 0.08\n",
    "\n",
    "# Características manuales (si prefieres elegirlas tú mismo)\n",
    "manual_features = [\"alcohol_density_ratio\", \"volatile_acidity\", \"sulfur_ratio\"]\n",
    "\n",
    "# Flag para elegir método de selección\n",
    "usar_seleccion_manual = False  # True = manual, False = automática\n",
    "\n",
    "# Bucle para probar cada modelo\n",
    "for nombre, modelo in modelos.items():\n",
    "    param_grid = param_grids[nombre]  # Grid correspondiente al modelo\n",
    "\n",
    "    # Obtener las características seleccionadas (manual o automática)\n",
    "    if usar_seleccion_manual:\n",
    "        selected_features = manual_features\n",
    "    else:\n",
    "        # Selección automática basada en la importancia\n",
    "        top_features = importancias_df[importancias_df[\"Importance\"] > umbral_importancia][\"Feature\"].tolist()\n",
    "        selected_features = top_features\n",
    "\n",
    "    # Filtrar conjuntos de entrenamiento y prueba\n",
    "    X_train_filtrado = X_train[selected_features]\n",
    "    X_test_filtrado = X_test[selected_features]\n",
    "\n",
    "    # Probar con cada modo\n",
    "    for modo in modos:\n",
    "        f1, best_params, best_model = probar_modelo_con_random_search(\n",
    "            modelo,\n",
    "            X_train_filtrado,\n",
    "            y_train,\n",
    "            X_test_filtrado,\n",
    "            y_test,\n",
    "            param_distributions=param_grids[nombre],\n",
    "            n_iter=50,  # Cambia si necesitas ajustar el número de iteraciones\n",
    "            modo=modo\n",
    "        )\n",
    "        resultados.append({\n",
    "            \"Modelo\": nombre,\n",
    "            \"Modo\": modo,\n",
    "            \"F1-Weighted\": f1,\n",
    "            \"Mejores Hiperparámetros\": best_params\n",
    "        })\n",
    "\n",
    "        # Guardar el modelo ajustado\n",
    "        modelos[nombre] = best_model\n",
    "\n",
    "# Identificar el modelo con mejor F1-Weighted\n",
    "mejor_modelo = max(resultados, key=lambda x: x['F1-Weighted'])\n",
    "nombre_modelo_ganador = mejor_modelo['Modelo']\n",
    "\n",
    "print(f\"El modelo ganador es: {nombre_modelo_ganador}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones del Proceso de Selección y Evaluación\n",
    "\n",
    "Tras ejecutar el bloque de código, se obtuvieron los siguientes resultados y conclusiones clave:\n",
    "\n",
    "1. **Mejor Modelo Identificado**:\n",
    "   - El modelo con mejor rendimiento fue el **Random Forest**, basado en su puntuación más alta en la métrica `F1-Weighted`. Esto refuerza su capacidad para manejar el problema actual, especialmente con las características seleccionadas.\n",
    "\n",
    "2. **Método de Selección de Características**:\n",
    "   - El uso de selección automática de características (umbral de importancia > 0.08) permitió identificar las variables más relevantes, asegurando un enfoque optimizado en el modelo.\n",
    "   - Las características seleccionadas automáticamente incluyeron variables clave como **alcohol**, **volatile_acidity**, y **density**, mientras que la selección manual se mantuvo opcional para escenarios específicos.\n",
    "\n",
    "3. **Impacto de los Modos de Balanceo**:\n",
    "   - Se probaron dos modos principales: `balance` y `ninguno`. Aunque `oversampling` se descartó debido a su rendimiento inferior en pruebas previas, los resultados muestran que el modo `balance` sigue siendo una opción sólida para ciertos modelos.\n",
    "\n",
    "4. **Optimización con Random Search**:\n",
    "   - La búsqueda aleatoria (`Random Search`) ajustó eficazmente los hiperparámetros, maximizando el rendimiento de cada modelo y proporcionando los mejores parámetros para el modelo ganador.\n",
    "\n",
    "5. **Resultados Destacados**:\n",
    "   - Los resultados incluyen la métrica `F1-Weighted` para cada modelo y modo, así como los mejores hiperparámetros encontrados. Estos datos son útiles para documentar y reproducir el experimento.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Mostrar Resultados Ordenados por F1-Weighted**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En este bloque, se organizan y visualizan los resultados de los modelos, ordenándolos según la métrica `F1-Weighted`. Esto permite ver claramente cuál fue el modelo con mejor rendimiento.\n",
    "\n",
    "1. **Creación de DataFrame con resultados**:\n",
    "   - Los resultados almacenados en la lista `resultados` se convierten en un DataFrame de `pandas` para facilitar su visualización.\n",
    "   \n",
    "2. **Ordenación de los resultados**:\n",
    "   - Los resultados se ordenan por la puntuación `F1-Weighted` de mayor a menor, para destacar el modelo con mejor rendimiento.\n",
    "\n",
    "3. **Ajuste de opciones de visualización**:\n",
    "   - Se configuran opciones de `pandas` para mostrar todas las filas, columnas, y evitar que los resultados se corten. Esto asegura que la tabla de resultados se vea completa sin limitaciones de visualización.\n",
    "\n",
    "4. **Mostrar los resultados**:\n",
    "   - Finalmente, se muestra el DataFrame con los resultados completos utilizando `display(resultados_df)`.\n",
    "\n",
    "Este paso permite ver todos los modelos evaluados junto con sus métricas, comparándolos de manera clara.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Modo</th>\n",
       "      <th>F1-Weighted</th>\n",
       "      <th>Mejores Hiperparámetros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.695164</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.689034</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.687034</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.681682</td>\n",
       "      <td>{'n_estimators': 150, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline XGBoost</td>\n",
       "      <td>Ninguno</td>\n",
       "      <td>0.666304</td>\n",
       "      <td>Sin GridSearch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.664431</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.658129</td>\n",
       "      <td>{'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.656097</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.641995</td>\n",
       "      <td>{'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.633434</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.603245</td>\n",
       "      <td>{'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 10, 'colsample_bytree': 0.7, 'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.597282</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.555762</td>\n",
       "      <td>{'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 10, 'colsample_bytree': 0.7, 'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo     Modo  F1-Weighted                                                                                                             Mejores Hiperparámetros\n",
       "0       Random Forest  balance     0.695164                                             {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}\n",
       "1       Random Forest  ninguno     0.689034                                             {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
       "2       Random Forest  balance     0.687034                                               {'n_estimators': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20}\n",
       "3       Random Forest  ninguno     0.681682                                               {'n_estimators': 150, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20}\n",
       "4    Baseline XGBoost  Ninguno     0.666304                                                                                                                      Sin GridSearch\n",
       "5   Gradient Boosting  ninguno     0.664431                                                                         {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
       "6   Gradient Boosting  ninguno     0.658129                                                       {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1}\n",
       "7   Gradient Boosting  balance     0.656097                                                                         {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
       "8   Gradient Boosting  balance     0.641995                                                       {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1}\n",
       "9             XGBoost  ninguno     0.633434                                  {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1}\n",
       "10            XGBoost  ninguno     0.603245  {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 10, 'colsample_bytree': 0.7, 'alpha': 0.1}\n",
       "11            XGBoost  balance     0.597282                                  {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1}\n",
       "12            XGBoost  balance     0.555762  {'subsample': 0.8, 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 10, 'colsample_bytree': 0.7, 'alpha': 0.1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostrar resultados ordenados por f1-weighted\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "resultados_df = resultados_df.sort_values(by='F1-Weighted', ascending=False)\n",
    "resultados_df = resultados_df.reset_index(drop=True)\n",
    "# Mostrar todas las filas\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# Mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Mostrar todas las columnas\n",
    "pd.set_option('display.width', None)\n",
    "# Mostrar todos los resultados\n",
    "pd.set_option('display.max_rows', None)\n",
    "# Evitar que las columnas se corten\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "display(resultados_df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones de los Resultados Ordenados por `F1-Weighted`\n",
    "\n",
    "Tras analizar los resultados de los modelos evaluados, se pueden destacar las siguientes conclusiones:\n",
    "\n",
    "1. **Mejor Modelo y Configuración**:\n",
    "   - El **Random Forest** con el modo `balance` obtuvo la mejor puntuación de `F1-Weighted` (**0.695164**) utilizando los siguientes hiperparámetros:\n",
    "     - `n_estimators`: 200\n",
    "     - `min_samples_split`: 5\n",
    "     - `min_samples_leaf`: 1\n",
    "     - `max_depth`: None\n",
    "\n",
    "2. **Comparación entre Modos**:\n",
    "   - En el caso del **Random Forest**, el modo `balance` mostró consistentemente mejores resultados que el modo `ninguno`.\n",
    "   - Para otros modelos, como **Gradient Boosting** y **XGBoost**, el impacto del modo `balance` fue menor o incluso desfavorable en comparación con el modo `ninguno`.\n",
    "\n",
    "3. **Diferencias entre Modelos**:\n",
    "   - Aunque el **Random Forest** lidera con un rendimiento superior, otros modelos como **Gradient Boosting** alcanzaron puntuaciones competitivas (ej., **0.664431** con modo `ninguno` y ajustes óptimos).\n",
    "   - Los modelos **XGBoost** no lograron superar a los mejores resultados de **Random Forest** ni **Gradient Boosting**, lo que sugiere que podrían requerir ajustes adicionales o modificaciones en el preprocesamiento de datos.\n",
    "\n",
    "4. **Baseline XGBoost**:\n",
    "   - El modelo de línea base (**Baseline XGBoost**) se mantiene como una referencia con un `F1-Weighted` de **0.666304**, mostrando que la configuración inicial es razonablemente competitiva frente a modelos más ajustados.\n",
    "\n",
    "5. **Relevancia del Grid Search**:\n",
    "   - Los hiperparámetros obtenidos mediante el `Random Search` permitieron mejorar sustancialmente el rendimiento de los modelos, especialmente en el caso de **Random Forest** y **Gradient Boosting**.\n",
    "\n",
    "\n",
    "### Resultados Destacados\n",
    "\n",
    "| Modelo             | Modo     | F1-Weighted | Mejores Hiperparámetros                                                                |\n",
    "|--------------------|----------|-------------|---------------------------------------------------------------------------------------|\n",
    "| Random Forest      | balance  | 0.695164    | {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None} |\n",
    "| Random Forest      | ninguno  | 0.689034    | {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None} |\n",
    "| Random Forest      | balance  | 0.687034    | {'n_estimators': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 20} |\n",
    "| Gradient Boosting  | ninguno  | 0.664431    | {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}                           |\n",
    "| Baseline XGBoost   | Ninguno  | 0.666304    | Sin GridSearch                                                                        |\n",
    "| XGBoost            | ninguno  | 0.633434    | {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1} |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Selección de Características y Evaluación de Modelos con Métodos L1 e Importancia**\n",
    "\n",
    "En este bloque, se aplican dos métodos de selección de características para evaluar su impacto en el rendimiento de los modelos:\n",
    "\n",
    "1. **Selección basada en L1**:\n",
    "   - Utilizamos un modelo de regresión logística con penalización L1 para realizar la selección de características. La penalización L1 puede reducir los coeficientes de algunas características a cero, lo que ayuda a seleccionar solo las características más relevantes.\n",
    "   - Se seleccionan las características cuyo coeficiente absoluto es mayor que un umbral de 0.01.\n",
    "   - Tras la selección, los conjuntos de datos de entrenamiento y prueba se ajustan a las características seleccionadas.\n",
    "\n",
    "2. **Selección basada en Importancia**:\n",
    "   - Usamos un clasificador `RandomForestClassifier` para calcular la importancia de las características. Las características cuya importancia es superior a 0.08 se seleccionan para el modelo.\n",
    "   - Al igual que en el caso de L1, los conjuntos de datos de entrenamiento y prueba se ajustan a las características seleccionadas.\n",
    "\n",
    "3. **Evaluación de Modelos**:\n",
    "   - Para cada método de selección, se evalúan los modelos utilizando las características seleccionadas, con dos estrategias de balanceo: **ninguno** y **balance**.\n",
    "   - Se realiza una búsqueda aleatoria de hiperparámetros con `RandomizedSearchCV`, y se guarda el modelo con la mejor puntuación `F1-Weighted`.\n",
    "\n",
    "4. **Visualización de Resultados**:\n",
    "   - Los resultados de todos los modelos se almacenan y se visualizan en un DataFrame ordenado por la métrica `F1-Weighted`, lo que facilita la comparación entre los modelos y métodos de selección.\n",
    "\n",
    "Este bloque permite evaluar el impacto de la selección de características sobre el rendimiento de los modelos, ayudando a entender qué método de selección mejora más los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas con L1: ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 16 is smaller than n_iter=50. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 16 is smaller than n_iter=50. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=50. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=50. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 32 is smaller than n_iter=50. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 32 is smaller than n_iter=50. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas por importancia: ['volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 16 is smaller than n_iter=50. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 16 is smaller than n_iter=50. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=50. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=50. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 32 is smaller than n_iter=50. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sopor\\anaconda3\\envs\\phishing\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 32 is smaller than n_iter=50. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Método Selección</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Modo</th>\n",
       "      <th>F1-Weighted</th>\n",
       "      <th>Mejores Hiperparámetros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.698552</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>importancia</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.697135</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.696831</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>importancia</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.691874</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>importancia</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.663975</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>importancia</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.662803</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L1</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.646234</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L1</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.641446</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L1</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.637021</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>importancia</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>ninguno</td>\n",
       "      <td>0.626176</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L1</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.608429</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>importancia</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>balance</td>\n",
       "      <td>0.598990</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Método Selección             Modelo     Modo  F1-Weighted                                                                             Mejores Hiperparámetros\n",
       "0                L1      Random Forest  ninguno     0.698552             {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
       "6       importancia      Random Forest  ninguno     0.697135             {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
       "1                L1      Random Forest  balance     0.696831             {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
       "7       importancia      Random Forest  balance     0.691874             {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n",
       "8       importancia  Gradient Boosting  ninguno     0.663975                                         {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
       "9       importancia  Gradient Boosting  balance     0.662803                                         {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
       "3                L1  Gradient Boosting  balance     0.646234                                         {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
       "4                L1            XGBoost  ninguno     0.641446  {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1}\n",
       "2                L1  Gradient Boosting  ninguno     0.637021                                         {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1}\n",
       "10      importancia            XGBoost  ninguno     0.626176  {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 1.0}\n",
       "5                L1            XGBoost  balance     0.608429  {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1}\n",
       "11      importancia            XGBoost  balance     0.598990  {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'lambda': 1, 'gamma': 0, 'alpha': 0.1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Crear el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar el escalador solo con los datos de entrenamiento y transformar\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformar los datos de prueba usando el mismo escalador\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Resultado por cada método de selección\n",
    "resultados_totales = []\n",
    "\n",
    "# Métodos de selección\n",
    "metodos_seleccion = [\"L1\", \"importancia\"]\n",
    "\n",
    "for metodo_seleccion in metodos_seleccion:\n",
    "    if metodo_seleccion == \"L1\":\n",
    "        try:\n",
    "            # Selección basada en L1\n",
    "            l1_model = LogisticRegression(penalty='l1', solver='liblinear', random_state=SEED, max_iter=1000)\n",
    "            l1_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            coeficientes = np.abs(l1_model.coef_).sum(axis=0)\n",
    "            selected_features = X_train.columns[coeficientes > 0.01]\n",
    "            print(f\"Características seleccionadas con L1: {selected_features.tolist()}\")\n",
    "\n",
    "            X_train_seleccion = X_train[selected_features]\n",
    "            X_test_seleccion = X_test[selected_features]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en L1: {e}\")\n",
    "            continue\n",
    "\n",
    "    elif metodo_seleccion == \"importancia\":\n",
    "        # Selección basada en importancia\n",
    "        rf_model = RandomForestClassifier(random_state=SEED)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        importancias = rf_model.feature_importances_\n",
    "        selected_features = X_train.columns[importancias > 0.08]\n",
    "        print(f\"Características seleccionadas por importancia: {selected_features.tolist()}\")\n",
    "\n",
    "        X_train_seleccion = X_train[selected_features]\n",
    "        X_test_seleccion = X_test[selected_features]\n",
    "\n",
    "    else:\n",
    "        print(f\"Método no válido: {metodo_seleccion}\")\n",
    "        continue\n",
    "\n",
    "    # Evaluar los modelos usando las características seleccionadas\n",
    "    for nombre, modelo in modelos.items():\n",
    "        for modo in [\"ninguno\", \"balance\"]:\n",
    "            f1, best_params, best_model = probar_modelo_con_random_search(\n",
    "                modelo,\n",
    "                X_train_seleccion,\n",
    "                y_train,\n",
    "                X_test_seleccion,\n",
    "                y_test,\n",
    "                param_distributions=param_grids[nombre],\n",
    "                n_iter=50,\n",
    "                modo=modo\n",
    "            )\n",
    "            resultados_totales.append({\n",
    "                \"Método Selección\": metodo_seleccion,\n",
    "                \"Modelo\": nombre,\n",
    "                \"Modo\": modo,\n",
    "                \"F1-Weighted\": f1,\n",
    "                \"Mejores Hiperparámetros\": best_params\n",
    "            })\n",
    "\n",
    "# Mostrar resultados\n",
    "resultados_df = pd.DataFrame(resultados_totales)\n",
    "display(resultados_df.sort_values(by=\"F1-Weighted\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones del Proceso de Selección de Características y Evaluación\n",
    "\n",
    "Tras aplicar los métodos de selección de características (`L1` e `importancia`) y evaluar los modelos con cada combinación, se destacan las siguientes conclusiones:\n",
    "\n",
    "1. **Mejor Método y Modelo**:\n",
    "   - El método de selección **L1** combinado con el modelo **Random Forest** en modo `ninguno` obtuvo la mejor puntuación de `F1-Weighted` (**0.698552**), utilizando los siguientes hiperparámetros:\n",
    "     - `n_estimators`: 200\n",
    "     - `min_samples_split`: 2\n",
    "     - `min_samples_leaf`: 1\n",
    "     - `max_depth`: None\n",
    "\n",
    "2. **Impacto de los Métodos de Selección**:\n",
    "   - El método basado en **L1** mostró un rendimiento ligeramente superior al método basado en **importancia**, especialmente con el modelo **Random Forest**.\n",
    "   - Sin embargo, ambos métodos lograron resultados competitivos, destacando la efectividad de las características seleccionadas para este problema.\n",
    "\n",
    "3. **Comparación entre Modelos**:\n",
    "   - El **Random Forest** dominó en ambas estrategias de selección y modos de balanceo, consolidándose como el modelo más eficaz.\n",
    "   - Los modelos **Gradient Boosting** y **XGBoost** obtuvieron puntuaciones más bajas en comparación con **Random Forest**, aunque el método basado en **importancia** permitió a **Gradient Boosting** alcanzar un rendimiento razonable (hasta **0.663975**).\n",
    "\n",
    "4. **Modos de Balanceo**:\n",
    "   - El modo `ninguno` superó al modo `balance` en la mayoría de los casos, especialmente para el modelo **Random Forest**, lo que sugiere que los datos originales ya presentan una distribución adecuada para este modelo.\n",
    "\n",
    "5. **Relevancia de los Hiperparámetros**:\n",
    "   - La búsqueda aleatoria (`Random Search`) permitió identificar configuraciones óptimas para cada modelo, maximizando su rendimiento con las características seleccionadas.\n",
    "\n",
    "\n",
    "### Resultados Destacados\n",
    "\n",
    "| Método Selección | Modelo             | Modo     | F1-Weighted | Mejores Hiperparámetros                                                                |\n",
    "|-------------------|--------------------|----------|-------------|---------------------------------------------------------------------------------------|\n",
    "| L1               | Random Forest      | ninguno  | 0.698552    | {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None} |\n",
    "| importancia       | Random Forest      | ninguno  | 0.697135    | {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None} |\n",
    "| L1               | Random Forest      | balance  | 0.696831    | {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None} |\n",
    "| importancia       | Random Forest      | balance  | 0.691874    | {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None} |\n",
    "| importancia       | Gradient Boosting  | ninguno  | 0.663975    | {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}                           |\n",
    "| importancia       | Gradient Boosting  | balance  | 0.662803    | {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustes Finales y Selección del Modelo\n",
    "\n",
    "1. **Modelo Seleccionado**:\n",
    "   - Finalmente, el modelo seleccionado es **Random Forest** con el método de selección basado en **L1** y sin aplicar balanceo (`ninguno`). Este modelo demostró ser el más eficaz, alcanzando el mejor rendimiento en la métrica `F1-Weighted`.\n",
    "\n",
    "2. **Eliminación de Duplicados**:\n",
    "   - Se ha desactivado la eliminación de duplicados debido a que perjudicaba el rendimiento del modelo, posiblemente por la pérdida de datos útiles para la clasificación.\n",
    "\n",
    "3. **Tratamiento de Atípicos**:\n",
    "   - Se ha desactivado el tratamiento de atípicos ya que resultaba contraproducente, posiblemente por la eliminación de casos importantes que el modelo utiliza para aprender patrones.\n",
    "\n",
    "4. **Combinación de Variables**:\n",
    "   - La combinación de variables también se desactivó, ya que no aportaba mejoras al rendimiento y en algunos casos añadía ruido innecesario al modelo.\n",
    "\n",
    "5. **Escalado y Transformaciones**:\n",
    "\n",
    "   - Se mantuvieron las transformaciones, pero se desactivó el escalado de variables.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
